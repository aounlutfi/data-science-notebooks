{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599551516887",
   "display_name": "Python 3.7.1 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE    = 299\n",
    "BATCH       = 64\n",
    "EPOCHS_a    = 20\n",
    "EPOCHS_b    = 10\n",
    "SPLIT       = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(validation_split=SPLIT)\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "train_it = train_datagen.flow_from_directory('data/train/', class_mode='categorical', batch_size=BATCH, target_size=(IMG_SIZE, IMG_SIZE), subset=\"training\")\n",
    "val_it = train_datagen.flow_from_directory('data/train/', class_mode='categorical', batch_size=BATCH, target_size=(IMG_SIZE, IMG_SIZE), subset=\"validation\")\n",
    "test_it = test_datagen.flow_from_directory('data/test/', class_mode='categorical', batch_size=BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batchX, batchy = train_it.next()\n",
    "NUM_CLASSES = batchy.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes, augment=False):\n",
    "    x = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    model = InceptionResNetV2(include_top=False, input_tensor=x, weights=\"imagenet\")\n",
    "\n",
    "    # Freeze the pretrained weights\n",
    "    model.trainable = False\n",
    "\n",
    "    # Rebuild top\n",
    "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    top_dropout_rate = 0.4\n",
    "    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "    # Compile\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"Model\")\n",
    "    optimizer = tf.keras.optimizers.Adamax(learning_rate=1e-2)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def plot_hist(hist):\n",
    "    plt.plot(hist.history[\"accuracy\"])\n",
    "    plt.plot(hist.history[\"val_accuracy\"])\n",
    "    plt.title(\"model accuracy\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "    plt.show()\n",
    "\n",
    "def unfreeze_model(model):\n",
    "    # We unfreeze the top 20 layers while leaving BatchNorm layers frozen\n",
    "    for layer in model.layers[-20:]:\n",
    "        if not isinstance(layer, layers.BatchNormalization):\n",
    "            layer.trainable = True\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adamax(learning_rate=1e-4)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_a = build_model(num_classes=NUM_CLASSES, augmentation=False)\n",
    "hist = model_a.fit(train_it, epochs=EPOCHS_a, validation_data=val_it, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_a = model_a.evaluate(test_it)\n",
    "results_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_b = unfreeze_model(model_a)\n",
    "hist = model_b.fit(train_it, epochs=EPOCHS_b, validation_data=val_it, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_b = model_b.evaluate(test_it)\n",
    "results_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results_a[1] > results_b[1]:\n",
    "    model_a.save('model.h5')\n",
    "else:\n",
    "    model_b.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}