{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "Python 3.8.2 64-bit ('venv': venv)",
   "display_name": "Python 3.8.2 64-bit ('venv': venv)",
   "metadata": {
    "interpreter": {
     "hash": "6704a13a11f20111acd916d3e024303c69ba0f7542ff959e77e5fa0d802aa562"
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, explained_variance_score\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "fname = 'data.csv'\n",
    "LABEL = 'label'\n",
    "SPLIT = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(fname)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column order in CSV file\n",
    "column_names = data.columns\n",
    "\n",
    "\n",
    "Y = data[LABEL]\n",
    "X = data.drop(columns=LABEL)\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'LR':LogisticRegression(), 'SVR':SVR(), 'MLP':MLPRegressor(), 'GBT':GradientBoostingRegressor(), 'RF': RandomForestRegressor()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for m in tqdm(models):\n",
    "    model = models[m]\n",
    "    scoring = ['explained_variance', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "    score = cross_validate(model, X, Y, scoring=scoring, cv=5)\n",
    "    scores = [] \n",
    "    for k in score.keys():\n",
    "        scores.append(np.mean(score[k]))\n",
    "\n",
    "    results.append(scores)\n",
    "results = pd.DataFrame(results, columns = score.keys(), index=list(models.keys()))\n",
    "results['test_explained_variance'] = -results['test_explained_variance']\n",
    "results['test_neg_mean_absolute_error'] = -results['test_neg_mean_absolute_error']\n",
    "results['test_neg_mean_squared_error'] = np.sqrt(-results['test_neg_mean_squared_error'])\n",
    "results['test_r2'] = -results['test_r2']\n",
    "results = results.sort_values('test_neg_mean_absolute_error')\n",
    "best = results.index[0]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "learning_rate = [0.5, 0.1, 0.05, 0.01, 0.001]\n",
    "loss = ['ls', 'lad', 'huber', 'quantile']\n",
    "\n",
    "penalty = ['l1', 'l2', 'elasticnet', 'none']\n",
    "C= [0.1, 0.5, 1, 2, 5, 10]\n",
    "\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "degree = [2, 3, 4, 5, 6]\n",
    "gamma = ['scale', 'auto']\n",
    "epsilon = [0.5, 0.1, 0.05, 0.01, 0.001]\n",
    "\n",
    "hidden_layer_sizes = [(10,), (100,), (200,), (10, 10), (50, 50), (100, 100), (100, 100, 100), (50, 100, 50)]\n",
    "activation = ['logistic', 'tanh', 'relu']\n",
    "solver = ['lbfgs', 'sgd', 'adam']\n",
    "batch_size = [32, 64, 128, 256]\n",
    "learning_rate_schedule = ['constant', 'invscaling', 'adaptive']\n",
    "\n",
    "\n",
    "rf_grid = {'n_estimators': n_estimators,\n",
    "    'max_features': max_features,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'bootstrap': bootstrap}\n",
    "\n",
    "gbr_grid = {'n_estimators': n_estimators,\n",
    "    'loss': loss,\n",
    "    'learning_rate': learning_rate,\n",
    "    'max_features': max_features,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "lr_grid = {\n",
    "    'penalty': penalty,\n",
    "    'C': C\n",
    "}\n",
    "\n",
    "svr_grid = {\n",
    "    'kernel': kernel,\n",
    "    'degree': degree,\n",
    "    'gamma': gamma,\n",
    "    'epsilon': epsilon\n",
    "}\n",
    "\n",
    "mlp_grid = {\n",
    "    'hidden_layer_sizes': hidden_layer_sizes,\n",
    "    'activation': activation ,\n",
    "    'solver': solver,\n",
    "    'batch_size': batch_size,\n",
    "    'learning_rate': learning_rate_schedule,\n",
    "    'learning_rate_init': learning_rate\n",
    "}\n",
    "\n",
    "grids = {'LR':lr_grid, 'SVR':svr_grid, 'MLP':mlp_grid, 'GBT':gbr_grid, 'RF': rf_grid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = models[best]\n",
    "best_model = RandomizedSearchCV(estimator = best_model, param_distributions = grids[best], n_iter = 100, cv = 3, verbose=5, random_state=42, n_jobs = 8)\n",
    "best_model.fit(X, Y)\n",
    "best_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = models[best].set_params(**best_model.best_params_)\n",
    "final_model.fit(x_train, y_train)\n",
    "prediction = final_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y_test, prediction)\n",
    "msre = np.sqrt(mean_squared_error(y_test, prediction))\n",
    "ev = explained_variance_score(y_test, prediction)\n",
    "print('MAE', mae)\n",
    "print('MSRE', msre)\n",
    "print('EV', ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}