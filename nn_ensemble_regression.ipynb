{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "\n",
    "from tensorflow.python.keras.models import save_model, load_model, Model\n",
    "from tensorflow.python.keras.layers import Dense, Input, BatchNormalization, Concatenate\n",
    "from tensorflow.python.keras.utils import plot_model\n",
    "from tensorflow.python.keras.callbacks import History, Callback\n",
    "from tensorflow.python.keras.optimizers import Adamax, Adam, Adagrad, SGD, RMSprop\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, explained_variance_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "_v = '_v0'\n",
    "fname = 'data.csv'\n",
    "bname = 'data_blind.csv'\n",
    "label_name = 'Label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=[label_name])\n",
    "Y = data[label_name]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, stratify=Y)\n",
    "input_shape = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input Shape\", input_shape)\n",
    "print(\"Input Mean\", np.mean(Y))\n",
    "print(\"Input std dev\", np.std(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = 'relu'\n",
    "optimizer = 'adamax'\n",
    "loss = 'mean_absolute_error'\n",
    "metrics = ['accuracy']\n",
    "lr = 0.01\n",
    "decay = 0.001\n",
    "batch = 1000\n",
    "epochs = 25\n",
    "intializer = 'glorot_normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_a(input, act, init):\n",
    "    d1 = Dense(1000, activation=act, kernel_initializer=init, name='Model_A_1')(input)\n",
    "    d2 = Dense(1000, activation=act, kernel_initializer=init, name='Model_A_2')(d1)\n",
    "    d3 = Dense(1000, activation=act, kernel_initializer=init, name='Model_A_3')(d2)\n",
    "    out = Dense(1, activation='sigmoid', kernel_initializer=init, name='Model_A_Output')(d3)\n",
    "    return out\n",
    "\n",
    "def model_b(input, act, init):\n",
    "    d1 = Dense(100, activation=act, kernel_initializer=init, name='Model_B_1')(input)\n",
    "    d2 = Dense(25, activation=act, kernel_initializer=init, name='Model_B_2')(d1)\n",
    "    d3 = Dense(10, activation=act, kernel_initializer=init, name='Model_B_3')(d2)\n",
    "    out = Dense(1, activation='sigmoid', kernel_initializer=init, name='Model_B_Output')(d3)\n",
    "    return out\n",
    "\n",
    "def model_c(input, act, init):\n",
    "    d1 = Dense(1000, activation=act, kernel_initializer=init, name='Model_C_1')(input)\n",
    "    d2 = Dense(500, activation=act, kernel_initializer=init, name='Model_C_2')(d1)\n",
    "    d3 = Dense(250, activation=act, kernel_initializer=init, name='Model_C_3')(d2)\n",
    "    d4 = Dense(100, activation=act, kernel_initializer=init, name='Model_C_4')(d3)\n",
    "    out = Dense(1, activation='sigmoid', kernel_initializer=init, name='Model_C_Output')(d4)\n",
    "    return out\n",
    "\n",
    "def model_d(input, act, init):\n",
    "    d1 = Dense(50, activation=act, kernel_initializer=init, name='Model_D_1')(input)\n",
    "    d2 = Dense(50, activation=act, kernel_initializer=init, name='Model_D_2')(d1)\n",
    "    d3 = Dense(50, activation=act, kernel_initializer=init, name='Model_D_3')(d2)\n",
    "    out = Dense(1, activation='sigmoid', kernel_initializer=init, name='Model_D_Output')(d3)\n",
    "    return out\n",
    "\n",
    "def model_e(input, act, init):\n",
    "    d1 = Dense(1000, activation=act, kernel_initializer=init, name='Model_E_1')(input)\n",
    "    out = Dense(1, activation='sigmoid', kernel_initializer=init, name='Model_E_Output')(d1)\n",
    "    return out\n",
    "\n",
    "def model_f(input, act, init):\n",
    "    d1 = Dense(50, activation=act, kernel_initializer=init, name='Model_F_1')(input)\n",
    "    d2 = Dense(50, activation=act, kernel_initializer=init, name='Model_F_2')(d1)\n",
    "    d3 = Dense(50, activation=act, kernel_initializer=init, name='Model_F_3')(d2)\n",
    "    d4 = Dense(50, activation=act, kernel_initializer=init, name='Model_F_4')(d3)\n",
    "    d5 = Dense(50, activation=act, kernel_initializer=init, name='Model_F_5')(d4)\n",
    "    d6 = Dense(50, activation=act, kernel_initializer=init, name='Model_F_6')(d5)\n",
    "    d7 = Dense(50, activation=act, kernel_initializer=init, name='Model_F_7')(d6)\n",
    "    out = Dense(1, activation='sigmoid', kernel_initializer=init, name='Model_F_Output')(d7)\n",
    "    return out\n",
    "\n",
    "def model_g(input, act, init):\n",
    "    d1 = Dense(100, activation='sigmoid', kernel_initializer=init, name='Model_G_1')(input)\n",
    "    out = Dense(1, activation='sigmoid', kernel_initializer=init, name='Model_G_Output')(d1)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(input_shape, loss, metrics, activation = 'relu', optimizer = 'adamax', lr = 0.01, decay=0.001, initializer='glorot_normal'):\n",
    "    \n",
    "    inputs = Input(shape=(input_shape,), name='Input')\n",
    "    norm = BatchNormalization(name='BatchNorm')(inputs)\n",
    "    a = model_a(norm, activation, initializer)\n",
    "    b = model_b(norm, activation, initializer)\n",
    "    c = model_c(norm, activation, initializer)\n",
    "    d = model_d(norm, activation, initializer)\n",
    "    e = model_e(norm, activation, initializer)\n",
    "    f = model_f(norm, activation, initializer)\n",
    "    g = model_g(norm, activation, initializer)\n",
    "    concat = Concatenate(name='Concat')([a, b, c, d, e, f, g])\n",
    "    out = Dense(1, activation='relu', kernel_initializer=initializer, name='Output')(concat)\n",
    "    \n",
    "    model = Model(inputs, out)\n",
    "    \n",
    "    if optimizer == 'adagrad':\n",
    "        opt = Adagrad(lr = lr, decay = decay)\n",
    "    elif optimizer == 'adam':\n",
    "        opt = Adam(lr = lr, decay = decay)\n",
    "    elif optimizer == 'adamax':\n",
    "        opt = Adamax(lr = lr, decay = decay)\n",
    "    elif optimizer == 'sgd':\n",
    "        opt == SGD(lr = lr, decay = decay)\n",
    "    elif optimzer == 'rmsprop':\n",
    "        opt = RMSprop(lr = lr, decay = decay)\n",
    "    else:\n",
    "        opt = 'sgd'\n",
    "\n",
    "    model.compile(loss=loss, optimizer=opt, metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ensemble(input_shape, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names = True, rankdir='TB', to_file='model' + _v + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=batch, epochs=epochs, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('nn_regression' + _v +'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loss', h.history['loss'][-1])\n",
    "print('Accuracy', h.history['acc'][-1])\n",
    "print('Validation Loss', h.history['val_loss'][-1])\n",
    "print('Validation Accuracy', h.history['val_acc'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h.history[metric_], label = metric_)\n",
    "plt.plot(h.history['val_' + metric_], label = 'val_' + metric_)\n",
    "plt.legend()\n",
    "plt.title(\"History\")\n",
    "plt.ylabel('metric')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h.history['loss'], label='loss')\n",
    "plt.plot(h.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.title(\"History\")\n",
    "plt.ylabel('metric')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('nn_classifier' + _v +'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res = model.predict(x_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y_res, y_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_res, y_test))\n",
    "e2 = explained_variance_score(y_res, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', mae)\n",
    "print('RMSE:', rmse)\n",
    "print('E2:', e2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('nn_regression' + _v +'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blind = pd.read_csv(bname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_blind = blind.drop(columns=[label_name])\n",
    "y_blind = blind[label_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_blind, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y_b, y_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_b, y_test))\n",
    "e2 = explained_variance_score(y_b, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', mae)\n",
    "print('RMSE:', rmse)\n",
    "print('E2:', e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
