{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "\n",
    "from tensorflow.python.keras.models import save_model, load_model, Model\n",
    "from tensorflow.python.keras.layers import Dense, Input, BatchNormalization, Concatenate\n",
    "from tensorflow.python.keras.utils import plot_model\n",
    "from tensorflow.python.keras.callbacks import History, Callback\n",
    "from tensorflow.python.keras.optimizers import Adamax, Adam, Adagrad, SGD, RMSprop\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "_v = '_v0'\n",
    "fname = 'data.csv'\n",
    "bname = 'data_blind.csv'\n",
    "label_name = 'Label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=[label_name])\n",
    "Y = data[label_name]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, stratify=Y)\n",
    "input_shape = x_train.shape[1]\n",
    "labels = np.unique(Y)\n",
    "class_weights = compute_class_weight(\"balanced\", labels, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input Shape\", input_shape)\n",
    "print(\"Labels\", labels)\n",
    "print(\"Class Weights\", class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = 'relu'\n",
    "optimizer = 'adamax'\n",
    "loss = 'binary_crossentropy'\n",
    "metrics = ['binary_accuracy']\n",
    "lr = 0.01\n",
    "decay = 0.001\n",
    "batch = 1000\n",
    "epochs = 25\n",
    "intializer = 'glorot_normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_a(input, act, init):\n",
    "    d1 = Dense(1000, activation=act, kernel_initializer=init, name='Model_A_1')(input)\n",
    "    d2 = Dense(1000, activation=act, kernel_initializer=init, name='Model_A_2')(d1)\n",
    "    d3 = Dense(1000, activation=act, kernel_initializer=init, name='Model_A_3')(d2)\n",
    "    out = Dense(1, activation='sigmoid', kernel_initializer=init, name='Model_A_Output')(d3)\n",
    "    return out\n",
    "\n",
    "def model_b(input, act, init):\n",
    "    d1 = Dense(100, activation=act, kernel_initializer=init, name='Model_B_1')(input)\n",
    "    d2 = Dense(25, activation=act, kernel_initializer=init, name='Model_B_2')(d1)\n",
    "    d3 = Dense(10, activation=act, kernel_initializer=init, name='Model_B_3')(d2)\n",
    "    out = Dense(1, activation='sigmoid', kernel_initializer=init, name='Model_B_Output')(d3)\n",
    "    return out\n",
    "\n",
    "def model_c(input, act, init):\n",
    "    d1 = Dense(1000, activation=act, kernel_initializer=init, name='Model_C_1')(input)\n",
    "    d2 = Dense(500, activation=act, kernel_initializer=init, name='Model_C_2')(d1)\n",
    "    d3 = Dense(250, activation=act, kernel_initializer=init, name='Model_C_3')(d2)\n",
    "    d4 = Dense(100, activation=act, kernel_initializer=init, name='Model_C_4')(d3)\n",
    "    out = Dense(1, activation='sigmoid', kernel_initializer=init, name='Model_C_Output')(d4)\n",
    "    return out\n",
    "\n",
    "def model_d(input, act, init):\n",
    "    d1 = Dense(50, activation=act, kernel_initializer=init, name='Model_D_1')(input)\n",
    "    d2 = Dense(50, activation=act, kernel_initializer=init, name='Model_D_2')(d1)\n",
    "    d3 = Dense(50, activation=act, kernel_initializer=init, name='Model_D_3')(d2)\n",
    "    out = Dense(1, activation='sigmoid', kernel_initializer=init, name='Model_D_Output')(d3)\n",
    "    return out\n",
    "\n",
    "def model_e(input, act, init):\n",
    "    d1 = Dense(1000, activation=act, kernel_initializer=init, name='Model_E_1')(input)\n",
    "    out = Dense(1, activation='sigmoid', kernel_initializer=init, name='Model_E_Output')(d1)\n",
    "    return out\n",
    "\n",
    "def model_f(input, act, init):\n",
    "    d1 = Dense(50, activation=act, kernel_initializer=init, name='Model_F_1')(input)\n",
    "    d2 = Dense(50, activation=act, kernel_initializer=init, name='Model_F_2')(d1)\n",
    "    d3 = Dense(50, activation=act, kernel_initializer=init, name='Model_F_3')(d2)\n",
    "    d4 = Dense(50, activation=act, kernel_initializer=init, name='Model_F_4')(d3)\n",
    "    d5 = Dense(50, activation=act, kernel_initializer=init, name='Model_F_5')(d4)\n",
    "    d6 = Dense(50, activation=act, kernel_initializer=init, name='Model_F_6')(d5)\n",
    "    d7 = Dense(50, activation=act, kernel_initializer=init, name='Model_F_7')(d6)\n",
    "    out = Dense(1, activation='sigmoid', kernel_initializer=init, name='Model_F_Output')(d7)\n",
    "    return out\n",
    "\n",
    "def model_g(input, act, init):\n",
    "    d1 = Dense(100, activation='sigmoid', kernel_initializer=init, name='Model_G_1')(input)\n",
    "    out = Dense(1, activation='sigmoid', kernel_initializer=init, name='Model_G_Output')(d1)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(input_shape, loss, metrics, activation = 'relu', optimizer = 'adamax', lr = 0.01, decay=0.001, initializer='glorot_normal'):\n",
    "    \n",
    "    inputs = Input(shape=(input_shape,), name='Input')\n",
    "    norm = BatchNormalization(name='BatchNorm')(inputs)\n",
    "    a = model_a(norm, activation, initializer)\n",
    "    b = model_b(norm, activation, initializer)\n",
    "    c = model_c(norm, activation, initializer)\n",
    "    d = model_d(norm, activation, initializer)\n",
    "    e = model_e(norm, activation, initializer)\n",
    "    f = model_f(norm, activation, initializer)\n",
    "    g = model_g(norm, activation, initializer)\n",
    "    concat = Concatenate(name='Concat')([a, b, c, d, e, f, g])\n",
    "    out = Dense(1, activation='sigmoid', kernel_initializer=initializer, name='Output')(concat)\n",
    "    \n",
    "    model = Model(inputs, out)\n",
    "    \n",
    "    if optimizer == 'adagrad':\n",
    "        opt = Adagrad(lr = lr, decay = decay)\n",
    "    elif optimizer == 'adam':\n",
    "        opt = Adam(lr = lr, decay = decay)\n",
    "    elif optimizer == 'adamax':\n",
    "        opt = Adamax(lr = lr, decay = decay)\n",
    "    elif optimizer == 'sgd':\n",
    "        opt == SGD(lr = lr, decay = decay)\n",
    "    elif optimzer == 'rmsprop':\n",
    "        opt = RMSprop(lr = lr, decay = decay)\n",
    "    else:\n",
    "        opt = 'sgd'\n",
    "\n",
    "    model.compile(loss=loss, optimizer=opt, metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ensemble(input_shape, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names = True, rankdir='TB', to_file='model' + _v + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=batch, epochs=epochs, verbose=1, shuffle=True, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('nn_classifier' + _v +'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = h.history.keys()\n",
    "for k in keys:\n",
    "    print(k, h.history[k][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h.history[k[0]], label = [k[0]])\n",
    "plt.plot(h.history[k[1]], label = [k[1]])\n",
    "plt.legend()\n",
    "plt.title(\"History\")\n",
    "plt.ylabel('metric')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h.history[k[2]], label = [k[2]])\n",
    "plt.plot(h.history[k[3]], label = [k[3]])\n",
    "plt.legend()\n",
    "plt.title(\"History\")\n",
    "plt.ylabel('metric')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('nn_classifier' + _v +'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res = model.predict(x_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.arange(0.05, 0.95, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = [] # change metrics\n",
    "recall = []\n",
    "f1 = []\n",
    "accuracy = []\n",
    "for t in tqdm(threshold):\n",
    "    Y_ = [0 if y_ < t else 1 for y_ in y_res]\n",
    "    p, r, f, s = precision_recall_fscore_support(y_test, Y_)\n",
    "    a = accuracy_score(y_test, Y_)\n",
    "    \n",
    "    precision.append(p[1])\n",
    "    recall.append(r[1])\n",
    "    accuracy.append(a)\n",
    "    f1.append(f[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argwhere(f1 == np.max(f1)).flatten()\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(threshold, recall, label='Recall')\n",
    "plt.plot(threshold, precision, label='Precision')\n",
    "plt.plot(threshold, f1, label='F1')\n",
    "plt.plot(threshold, accuracy, label='Accuracy')\n",
    "mx = 0\n",
    "thresh = None\n",
    "for i in idx:\n",
    "    if f1[i] > mx: mx = f1[i]; thresh = round(threshold[i], 2)\n",
    "    plt.plot(threshold[i], f1[i], 'ro')\n",
    "    plt.text(threshold[i], f1[i], str(round(f1[i], 3)))\n",
    "plt.title('Metrics')\n",
    "plt.ylabel('Metric')\n",
    "plt.xlabel('Threshold')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Threshold\", thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0 if _y < thresh else 1 for _y in y_res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y, y_test)\n",
    "report = classification_report(y, y_test, digits=3)\n",
    "cf = confusion_matrix(y, y_test)\n",
    "a = auc(y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report)\n",
    "print(\"Accuracy\", acc)\n",
    "print(\"AUC\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cf, xticklabels=['No ' + label_name, label_name], yticklabels=['No ' + label_name, label_name], annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('nn_classifier' + _v +'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blind = pd.read_csv(bname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_blind = blind.drop(columns=[label_name])\n",
    "y_blind = blind[label_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_blind, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_b = [0 if _y < thresh else 1 for _y in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_b, y_blind)\n",
    "report = classification_report(y_b, y_blind, digits=3)\n",
    "cf = confusion_matrix(y_b, y_blind)\n",
    "a = auc(y_b, y_blind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report)\n",
    "print(\"Accuracy\", acc)\n",
    "print(\"AUC\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cf, xticklabels=['No ' + label_name, label_name], yticklabels=['No ' + label_name, label_name], annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
